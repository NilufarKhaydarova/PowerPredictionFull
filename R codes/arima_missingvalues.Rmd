---
title: "R Notebook"
output: html_notebook
---

```{r}
library(lubridate)
library(forecast)
library(ggplot2)
library(naniar)
library(dplyr)


data <- read.csv("household_power_consumption.txt", header=TRUE, sep=";")

#convert into right data types
str(data)

data$Time <- gsub('\\.',':',data$Time)
data$Date <- gsub('/','-',data$Date)

data$DateTime <- as.POSIXct(as.character(paste(data$Date, data$Time)), format="%d-%m-%Y %H:%M:%S")

data <- subset( data, select = -c(Date, Time) )

data[1:6] <- lapply(data[1:6], as.numeric)

str(data)



```
```{r}
#reindex dataframe

data <-data %>% select(DateTime, everything())

head(data)
```


```{r}
#missing values

colSums(is.na(data))

```

```{r}
library(forecast)
library(ggplot2)
library(naniar)

gg_miss_upset(data)
```

```{r}
gg_miss_var(data)
```




```{r}
gg_miss_var_cumsum(data)
```
```{r}
gg_miss_span(data,
             span_every = 3000, 
             facet = DateTime)
```


```{r}
gg_miss_var(data, show_pct = TRUE)
```

```{r}
ggseasonplot(data)
```

```{r}
#arima model imputation
dataTS = ts(data)
arimaModel <- auto.arima(dataTS[,2])
model <- arimaModel$model

#Kalman smoothing
kal <- KalmanSmooth(dataTS, model, nit=0L )
erg <- kal$smooth  

for ( i in 1:length(model$Z)) {
       erg[,i] = erg[,i] * model$Z[i]
}
karima <-rowSums(erg)

for (i in 1:length(data)) {
  if (is.na(dataTS[i])) {
    dataTS[i] <- karima[i]
  }
}
#Original TimeSeries with imputed values
print(dataTS)
```
```{r}
colSums(is.na(dataTS))

```
```{r}

na_kalman <- function(x, model = "StructTS", smooth = TRUE, nit = -1, maxgap = Inf, ...) {
  data <- x


  #----------------------------------------------------------
  # Mulivariate Input
  # The next 20 lines are just for checking and handling multivariate input.
  #----------------------------------------------------------

  # Check if the input is multivariate
  if (!is.null(dim(data)[2]) && dim(data)[2] > 1) {
    # Go through columns and impute them by calling this function with univariate input
    for (i in 1:dim(data)[2]) {
      if (!anyNA(data[, i])) {
        next
      }
      # if imputing a column does not work - mostly because it is not numeric - the column is left unchanged
      tryCatch(data[, i] <- na_kalman(data[, i], model, smooth, nit, maxgap,...), error = function(cond) {
        warning(paste("imputeTS: No imputation performed for column", i, "because of this", cond), call. = FALSE)
      })
    }
    return(data)
  }


  #----------------------------------------------------------
  # Univariate Input
  # All relveant imputation / pre- postprocessing  code is within this part
  #----------------------------------------------------------

  else {
    missindx <- is.na(data)

    ##
    ## 1. Input Check and Transformation
    ##


    # 1.1 Check if NAs are present
    if (!anyNA(data)) {
      return(data)
    }

    # 1.2 special handling data types
    if (any(class(data) == "tbl")) {
      data <- as.vector(as.data.frame(data)[, 1])
    }

    # 1.3 Check for algorithm specific minimum amount of non-NA values
    if (sum(!missindx) < 3) {
      stop("Input data needs at least 3 non-NA data point for applying na_kalman")
    }


    # 1.4 Checks and corrections for wrong data dimension

    # Check if input dimensionality is not as expected
    if (!is.null(dim(data)[2]) && !dim(data)[2] == 1) {
      stop("Wrong input type for parameter x")
    }

    # Altering multivariate objects with 1 column (which are essentially
    # univariate) to be dim = NULL
    if (!is.null(dim(data)[2])) {
      data <- data[, 1]
    }

    # 1.5 Check if input is numeric
    if (!is.numeric(data)) {
      stop("Input x is not numeric")
    }

    # 1.6 Check if type of parameter smooth is correct
    if (!is.logical(smooth)) {
      stop("Parameter smooth must be of type logical ( TRUE / FALSE)")
    }

    # 1.7 Transformation to numeric as 'int' can't be given to KalmanRun
    data[1:length(data)] <- as.numeric(data)

    ##
    ## End Input Check and Transformation
    ##


    ##
    ## 2. Imputation Code
    ##

    # 2.1 Selection of state space model

    # State space representation of a arima model
    if (model[1] == "auto.arima") {
      mod <- forecast::auto.arima(data, ...)$model
    }
    # State space model, default is BSM - basic structural model
    else if (model[1] == "StructTS") {
      # Fallback, because for StructTS first value is not allowed to be NA
      if (is.na(data[1])) {
        data[1] <- na_locf(data, option = "nocb", na_remaining = "rev")[1]
      }
      mod <- stats::StructTS(data, ...)$model0
    }
    # User supplied model e.g. created with arima() or other state space models from other packages
    else {
      mod <- model
      if (length(mod) < 7) {
        stop("Parameter model has either to be \"StructTS\"/\"auto.arima\" or a user supplied model in
            form of a list with at least components T, Z, h , V, a, P, Pn specified")
      }

      if (is.null(mod$Z)) {
        stop("Something is wrong with the user supplied model. Either choose \"auto.arima\" or \"StructTS\"
             or supply a state space model with at least components T, Z, h , V, a, P, Pn as specified
             under Details on help page for KalmanLike")
      }
    }


    # 2.2 Selection if KalmanSmooth or KalmanRun

    if (smooth == TRUE) {
      kal <- stats::KalmanSmooth(data, mod, nit)
      erg <- kal$smooth # for kalmanSmooth
    }
    else {
      kal <- stats::KalmanRun(data, mod, nit)
      erg <- kal$states # for kalmanrun
    }

    # Check if everything is right with the model
    if (dim(erg)[2] != length(mod$Z)) {
      stop("Error with number of components $Z")
    }

    # 2.3 Getting Results

    # Out of all components in $states or$smooth only the ones
    # which have 1 or -1 in $Z are in the model
    # Therefore matrix multiplication is done
    karima <- erg[missindx, , drop = FALSE] %*% as.matrix(mod$Z)

    # Add imputations to the initial dataset
    data[missindx] <- karima

    ##
    ## End Imputation Code
    ##


    ##
    ## 3. Post Processing
    ##

    # 3.1 Check for Maxgap option

    # If maxgap = Inf then do nothing and when maxgap is lower than 0
    if (is.finite(maxgap) && maxgap >= 0) {

      # Get logical vector of the time series via is.na() and then get the
      # run-length encoding of it. The run-length encoding describes how long
      # the runs of FALSE and TRUE are
      rlencoding <- rle(is.na(x))

      # Runs smaller than maxgap (which shall still be imputed) are set FALSE
      rlencoding$values[rlencoding$lengths <= maxgap] <- FALSE

      # The original vector is being reconstructed by reverse.rls, only now the
      # longer runs are replaced now in the logical vector derived from is.na()
      # in the beginning all former NAs that are > maxgap are also FALSE
      en <- inverse.rle(rlencoding)

      # Set all positions in the imputed series with gaps > maxgap to NA
      # (info from en vector)
      data[en == TRUE] <- NA
    }

    ##
    ## End Post Processing
    ##


    ##
    ## 4. Final Output Formatting
    ##

    # Give back the object originally supplied to the function
    # (necessary for multivariate input with only 1 column)
    if (!is.null(dim(x)[2])) {
      x[, 1] <- data
      return(x)
    }

    ##
    ## End Final Output Formatting
    ##

    return(data)
  }
}

```

```{r}
dataTS = ts(data)

# Plot multivariate ts
plot(dataTS[,2:7])

# Run auto.arima on a single ts
arima_fit = auto.arima(dataTS[,1])

# Forecast for the next 10 time units
arima_forecast = forecast(arima_fit)

# Plot forecasts
plot(arima_forecast)
```

```{r}

colSums(is.na(dataTS))

